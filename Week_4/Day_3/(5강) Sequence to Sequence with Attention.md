# (5ê°•) Sequence to Sequence with Attention

Sequenceë¥¼ Encodingì™€ Decodingí•  ìˆ˜ ìˆëŠ” **sequence to sequence**ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.

**Sequence to sequence**ëŠ” encoderì™€ decoderë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ” frameworkìœ¼ë¡œ ëŒ€í‘œì ì¸ ìì—°ì–´ ì²˜ë¦¬ architecture ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. Encoderì™€ Decoderë¡œëŠ” ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì´ ì‚¬ìš©ë  ìˆ˜ ìˆì§€ë§Œ ì´ë²ˆ ì‹œê°„ì—ëŠ” **RNNê³¼ Attention**ì„ ê²°í•©í•œ sequence to sequence ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.

ì•ì„  ê°•ì˜ì—ì„œ ì„¤ëª…ë“œë ¸ë˜ ê²ƒì²˜ëŸ¼ RNN ëª¨ë¸ì´ ê°–ê³  ìˆëŠ” ë‹¨ì ì„ ë³´ì™„í•˜ê³ ì **Attention**(ë…¼ë¬¸ì—ì„œëŠ” alignmentë¡œ í‘œí˜„ë˜ê³  ìˆìŠµë‹ˆë‹¤) ê¸°ë²•ì´ ì²˜ìŒ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ Attentionì˜ ì¢…ë¥˜ì™€ ì´ë¥¼ í™œìš©í•œ translation taskì— ëŒ€í•´ì„œ ì•Œì•„ë´…ë‹ˆë‹¤

**Further Reading**

- [Sequence to sequence learning with neural networks, ICMLâ€™14](https://arxiv.org/abs/1409.3215)
- [Effective Approaches to Attention-based Neural Machine Translation, EMNLP 2015](https://arxiv.org/abs/1508.04025)
- [CS224n(2019)_Lecture8_NMT](https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture08-nmt.pdf)

---

## Seq2Seq with attention

### Seq2Seq Model

- It takes a `sequence of words` as input and gives `a sequence of words as output`
- It composed of an `encoder` and a `decoder`

![image](https://user-images.githubusercontent.com/38639633/108185462-aafd1580-714f-11eb-9311-cf58203c8b6a.png)

> Sequence to sequence learning with neural networks, ICMLâ€™14



### Seq2Seq Model with Attention

- attentionì€ encoder decoderì˜ `bottleneck` ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤.
- **Core idea :** Decoderì˜ ê° timestepì— ëŒ€í•˜ì—¬, src sequenceì˜ íŠ¹ì •í•œ ë¶€ë¶„ì— ì§‘ì¤‘í•œë‹¤ëŠ” ì•„ì´ë””ì–´

![](https://3.bp.blogspot.com/-3Pbj_dvt0Vo/V-qe-Nl6P5I/AAAAAAAABQc/z0_6WtVWtvARtMk0i9_AtLeyyGyV6AI4wCLcB/s1600/nmt-model-fast.gif)

- Use the attention distribution to take a weighted sum of the encoder hidden states
- The attention output mostly contains information the hidden states that received high attention

![attention](../../assets/img/boostcamp/attention.gif)

- Concatenate attention output with decoder hidden state, then use to compute $\hat{y}_1$as before
	- ì²« ë²ˆì§¸ Decoder hidden state $h_1^{(d)}$ëŠ” Encoder hidden stateë“¤ì˜ concatenate $[h_1^{(e)},h_2^{(e)},h_3^{(e)},h_4^{(e)}]$ì™€ Matrix ì—°ì‚°ì„ ì§„í–‰í•œë‹¤.
	- ìœ„ ê·¸ë¦¼ì—ì„œëŠ”  4 by 4 matrix(concatenate of encoder hidden state)ì™€ 4 by 1 matrix(decoder hidden state)ë¥¼ ê³±í•˜ê²Œ ëœë‹¤. 
	- ê·¸ ê²°ê³¼ë¡œ ë‚˜ì˜¨ 4 by 1 matrix(vector)ëŠ” encoderì˜ ê° timestepì— í•´ë‹¹í•˜ëŠ” `attention scores`ê°€ ëœë‹¤. 
	- ì´ë ‡ê²Œ ê³„ì‚°ëœ attention scoreëŠ” softmaxë¥¼ ê±°ì¹˜ê²Œ ëœë‹¤. 
	-  ê·¸ ê²°ê³¼ ê° tokenì— í•´ë‹¹í•˜ëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°ë¥¼ ì–»ê²Œë˜ê³ , ì´ ê°€ì¤‘ì¹˜ì™€ encoder hidden stateë¥¼ ë°˜ì˜í•œ `ê°€ì¤‘í‰ê· `ì„ ë°”íƒ•ì„ Attention output vector(Context vector)ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. 
	- ì´ë•Œ, `ATTENTION MODULE`ì€ encoder hidden stateë¡œ ë¶€í„° êµ¬í•´ì§€ëŠ” Attention scoreì™€ Attention distribution(softmax output) ë‘ ë¶€ë¶„ìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆë‹¤.
	- Attention moduleì˜ inputê³¼ outputì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 
		- input : decoderì˜ hidden state, encoder hidden stateì˜ concatenate
		- output : ê°€ì¤‘í‰ê· ìœ¼ë¡œ ê³„ì‚°ëœ output vector 1ê°œ
	- `output layer`ëŠ” Context vectorì™€ decoderì˜ hidden stateë¥¼ concatenateí•œ ë²¡í„°($\hat{y}_1$)ê°€ Inputìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤. 

- Training : Decoderì˜ inputìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë‹¨ì–´ë“¤ì€ ground truthë¡œ ë“¤ì–´ê°€ê²Œ ëœë‹¤. (Teacher forcing ë°©ì‹)
- Inference : ì´ë•ŒëŠ” ì²« ë²ˆì§¸ì˜ output ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë‘ë²ˆì§¸ input ë‹¨ì–´ë¡œ ì‚¬ìš©í•œë‹¤. 
- Teacher forcingì˜ ê²½ìš°, ì†ë„ëŠ” ë¹ ë¥´ì§€ë§Œ ì‹¤ì œ ì‚¬ìš©í–ˆì„ ë•Œ ê´´ë¦¬ê°€ ìˆì„ ìˆ˜ ìˆë‹¤. 



### Different Attention Mechanisms

- **`Luong attention`**: they get the decoder hidden state at time ğ‘¡, then calculate attention scores, and from that get the context vector which will be concatenated with hidden state of the decoder and then predict the output. 
- **`Bahdanau attention`**: At time **t**, we consider the hidden state of the decoder at time **t âˆ’ 1**. Then we calculate the alignment, context vectors as above. But then we concatenate this context with hidden state of the decoder at time t âˆ’ 1. So before the softmax, this concatenated vector goes inside a LSTM unit. 
- **Luong** has different types of alignments. **Bahdanau** has only a concat-score alignment model.

![image](https://user-images.githubusercontent.com/38639633/108210628-23270380-716f-11eb-8ce9-6bfedc98ca07.png)

- ë‹¤ì–‘í•œ ë°©ì‹ì˜ attention scoreë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì´ ì¡´ì¬í•œë‹¤. 



### Attention is Great!

- **Attention significantly improves NMT performance**
	- It is useful to allow the decoder to focus on particular parts of the source
- **Attention solves the bottleneck problem**
	- Attention allows the decoder to look directly at source; bypass the bottleneck
- **Attention helps with vanishing gradient problem**
	- Provides a shortcut to far-away states
- **Attention provides some interpretability**
	- By inspecting attention distribution, we can see what the decoder was focusing on
	- The network just learned alignment by itself



### Attention Examples in Machine Translation

- It properly learns grammatical orders of words
- It skips unnecessary words such as an article

![image](https://user-images.githubusercontent.com/38639633/108213315-38516180-7172-11eb-9635-cc7d93a84b46.png)

